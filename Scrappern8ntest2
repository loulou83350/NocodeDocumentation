import asyncio
from playwright.async_api import async_playwright
from docx import Document
import os

BASE_URL = "https://docs.n8n.io"

# Dossier de sortie
os.makedirs("n8n_docs", exist_ok=True)

async def scrape_n8n_docs():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto(BASE_URL)

        # On attend le menu latéral
        await page.wait_for_selector("nav a")

        # On récupère tous les liens du menu
        links = await page.eval_on_selector_all("nav a", "elements => elements.map(e => e.href)")
        print(f"{len(links)} liens trouvés dans le menu")

        # On supprime les doublons et liens externes
        links = list(set([link for link in links if link.startswith(BASE_URL)]))

        for idx, link in enumerate(links):
            await page.goto(link)
            await page.wait_for_selector("main")

            # Récupère le titre de la page
            title = await page.title()
            title = title.replace(" | n8n Docs", "").strip()

            # Récupère le contenu principal
            content = await page.inner_text("main")

            # Création du docx
            doc = Document()
            doc.add_heading(title, 0)
            doc.add_paragraph(content)

            filename = f"n8n_docs/{idx+1:03d}_{title[:50].replace(' ', '_').replace('/', '-')}.docx"
            doc.save(filename)
            print(f"✅ {filename} sauvegardé")

        await browser.close()

asyncio.run(scrape_n8n_docs())
